{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5b2ff4",
   "metadata": {},
   "source": [
    "# ДЗ1: Извлечение ключевых слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ecfcc",
   "metadata": {},
   "source": [
    "## 1. Создание мини-корпуса + 2. Самостоятельная разметка ключевых слов\n",
    "\n",
    "Корпус создан на основе трудов международной конференции «Корпусная лингвистика-2021» ([ссылка на сборник](https://elibrary.ru/item.asp?id=47945360)). Ключевые слова и тексты были скопированы из pdf-файла вручную. Из каждого текста были взяты только первая и последняя части (условно Введение и Заключение) для простоты анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4d92e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "corp_ling_dict = {\n",
    "    '1': {\n",
    "        'article_keywords': ['нкря', 'состав текстов', 'репрезентативность', 'сбалансированность'],\n",
    "        'my_keywords': ['нкря', 'корпус', 'репрезентативность', 'сбалансированность', 'объем корпуса'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '2': {\n",
    "        'article_keywords': ['синтаксис зависимостей', 'анафорическая разметка', 'лексико-функциональная разметка', \n",
    "                     'микросинтаксическая разметка', 'темпоральная разметка', 'эллипсис', 'поиск'],\n",
    "        'my_keywords': ['СинТагРус', 'разметка', 'доступность'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '3': {\n",
    "        'article_keywords': ['поверхностный синтаксический анализ', 'автоматическое извлечение конструкций', 'русский язык'],\n",
    "        'my_keywords': ['синтаксический анализ', 'конструкции', 'метод', 'русский язык'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '4': {\n",
    "        'article_keywords': ['концепт', 'дистрибутивный тезаурус', \n",
    "                     'сопоставительное исследование', 'языковая картина мира'],\n",
    "        'my_keywords': ['концепт', 'языковая картина мира', 'государство', 'лексема'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '5': {\n",
    "        'article_keywords': ['коллокации', 'база данных', 'словари', 'статистические методы', 'русский язык'],\n",
    "        'my_keywords': ['лексическая сочетаемость', 'коллокации', 'база данных'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '6': {\n",
    "        'article_keywords': ['гендерный стереотип', 'гендерная идентичность', 'корпусная лингвистика', '«Твиттер»'],\n",
    "        'my_keywords': ['блог', 'образ', 'стереотип', 'твиты', 'женщины-политики'],\n",
    "        'text': ''\n",
    "    },\n",
    "    '7': {\n",
    "        'article_keywords': ['антропоморфные метафоры', 'китайский язык', 'русский язык', 'корпусный анализ'],\n",
    "        'my_keywords': ['китайский язык', 'русский язык', 'политический дискурс', 'метафора'],\n",
    "        'text': ''\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1aa1fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = 0\n",
    "for i in corp_ling_dict.keys():\n",
    "    with open(f'corpus/{i}.txt', encoding='utf-8') as f:\n",
    "        text = f.read().replace('-\\n', '').replace('\\xa0', ' ').replace('\\n', ' ')\n",
    "    corp_ling_dict[i]['text'] = text\n",
    "    corp_ling_dict[i]['keywords'] = set(corp_ling_dict[i]['article_keywords']) | set(corp_ling_dict[i]['my_keywords'])\n",
    "    num_tokens += len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "6c23a7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В корпусе 3114 токенов\n"
     ]
    }
   ],
   "source": [
    "print(f'В корпусе {num_tokens} токенов')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4bbe2e",
   "metadata": {},
   "source": [
    "## 3. Методы извлечения ключевых слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7eaf4b",
   "metadata": {},
   "source": [
    "### 3.1. RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac7a52d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-rake\n",
      "  Downloading python_rake-1.5.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: python-rake\n",
      "Successfully installed python-rake-1.5.0\n"
     ]
    }
   ],
   "source": [
    "# установка\n",
    "!pip3 install python-rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0bf844e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/tasia/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import RAKE\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = stopwords.words('russian') + ['это', 'то', 'ты', 'мы', 'вы', 'я', 'он', 'она', 'оно', 'они']\n",
    "rake = RAKE.Rake(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2fa9f57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corp_ling_dict.keys():\n",
    "    rake_kw_list = rake.run(corp_ling_dict[i]['text'], maxWords=3, minFrequency=2)\n",
    "    corp_ling_dict[i]['rake_kw'] = [w for w, i in rake_kw_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d624820f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'автоматическое извлечение конструкций',\n",
       "  'конструкции',\n",
       "  'метод',\n",
       "  'поверхностный синтаксический анализ',\n",
       "  'русский язык',\n",
       "  'синтаксический анализ'},\n",
       " ['методы машинного обучения',\n",
       "  'др',\n",
       "  'см',\n",
       "  'например',\n",
       "  '[большакова',\n",
       "  'заметим'])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_ling_dict['3']['keywords'], corp_ling_dict['3']['rake_kw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "07cb666b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы было получше -- почистим\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "known_words = dict()\n",
    "m = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c6fe870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        if t.isalpha():\n",
    "            if t in known_words:\n",
    "                lemm = known_words[t]\n",
    "            else:\n",
    "                lemm = m.parse(t)[0].normal_form\n",
    "                known_words[t] = lemm\n",
    "            lemmas.append(lemm)\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4ac4d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corp_ling_dict.keys():\n",
    "    corp_ling_dict[i]['norm_text'] = normalize_text(corp_ling_dict[i]['text'])\n",
    "    rake_kw_list = rake.run(corp_ling_dict[i]['norm_text'], maxWords=3, minFrequency=2) \n",
    "    corp_ling_dict[i]['rake_kw'] = set([w for w, i in rake_kw_list[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3945036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'автоматическое извлечение конструкций',\n",
       "  'конструкции',\n",
       "  'метод',\n",
       "  'поверхностный синтаксический анализ',\n",
       "  'русский язык',\n",
       "  'синтаксический анализ'},\n",
       " {'синтаксический связь'})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_ling_dict['3']['keywords'], corp_ling_dict['3']['rake_kw']\n",
    "# ээээ у не то чтобы стало лучше..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4259dc",
   "metadata": {},
   "source": [
    "### 3.2. TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5bad6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting summa\n",
      "  Downloading summa-1.2.0.tar.gz (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m693.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from summa) (1.7.0)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in /Users/tasia/miniforge3/lib/python3.9/site-packages (from scipy>=0.19->summa) (1.22.3)\n",
      "Building wheels for collected packages: summa\n",
      "  Building wheel for summa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for summa: filename=summa-1.2.0-py3-none-any.whl size=54411 sha256=9fe8671093ad85d15e314d30e07e31fcccc89da4b9639e207e4aead4b5b6fda2\n",
      "  Stored in directory: /Users/tasia/Library/Caches/pip/wheels/ed/2c/5f/a0ccc5955d44d2cea78729f4425e73f818d2629517f7af0f8b\n",
      "Successfully built summa\n",
      "Installing collected packages: summa\n",
      "Successfully installed summa-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install summa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "293496fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from summa import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1464405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corp_ling_dict.keys():\n",
    "    tr_kw_string = keywords.keywords(corp_ling_dict[i]['norm_text'], language='russian', \n",
    "                              additional_stopwords=stops, scores=False)\n",
    "    corp_ling_dict[i]['tr_kw'] = set(tr_kw_string.split('\\n')[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ca298ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'автоматическое извлечение конструкций',\n",
       "  'конструкции',\n",
       "  'метод',\n",
       "  'поверхностный синтаксический анализ',\n",
       "  'русский язык',\n",
       "  'синтаксический анализ'},\n",
       " {'конструкция',\n",
       "  'метод весь',\n",
       "  'поиск синтаксически',\n",
       "  'проведение синтаксический анализ текст являться',\n",
       "  'работа'})"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_ling_dict['3']['keywords'], corp_ling_dict['3']['tr_kw']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd3e550",
   "metadata": {},
   "source": [
    "### 3.3. TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8307d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5a79a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [corp_ling_dict[i]['norm_text'] for i in corp_ling_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "200bf268",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "625852bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 6030)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "aeece0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9bfb22e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попытка в сортировку спарс без перевода в денс, ибо а в чем тогда смысл\n",
    "rows, cols = tfidf_matrix.nonzero()\n",
    "\n",
    "idx = defaultdict(list)\n",
    "for r, c, v in zip(rows, cols, tfidf_matrix.data):\n",
    "    idx[r].append((c, v))\n",
    "\n",
    "for r in idx.keys():\n",
    "    sorted_row = sorted(idx[r], key=lambda v: v[1], reverse=True)\n",
    "    idx[r] = [i for i, v in sorted_row[:5]]\n",
    "    corp_ling_dict[str(r + 1)]['tfidf_kw'] = set(feature_names[idx[r]].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8eee5f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'автоматическое извлечение конструкций',\n",
       "  'конструкции',\n",
       "  'метод',\n",
       "  'поверхностный синтаксический анализ',\n",
       "  'русский язык',\n",
       "  'синтаксический анализ'},\n",
       " {'конструкция',\n",
       "  'метод',\n",
       "  'синтаксический',\n",
       "  'синтаксический анализ',\n",
       "  'точность'})"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corp_ling_dict['3']['keywords'], corp_ling_dict['3']['tfidf_kw']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6f66a",
   "metadata": {},
   "source": [
    "## 4. Морфологические шаблоны\n",
    "\n",
    "В беседе в тг сказали, что можно уже из готовых keywords оставлять те, что удовлетворяют шаблонам. Но в моем случае keywords состоят уже из лемматизированных слов без дополнительной разметки. Поэтому я буду использовать только частеречные шаблоны (хотя в целом даже на основе такой информации можно делать выводы о синтаксических связях, см. мою с ЭС статью в сборнике по ссылке выше)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "015e0601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['синтаксический связь']\n",
      "[]\n",
      "[]\n",
      "['результат исследование']\n",
      "['политический дискурс', 'русский язык']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['синтаксический анализ']\n",
      "['картина мир', 'языковой картина']\n",
      "[]\n",
      "[]\n",
      "['политический дискурс']\n"
     ]
    }
   ],
   "source": [
    "for t in ['rake', 'tr', 'tfidf']:\n",
    "    for i in corp_ling_dict.keys():\n",
    "        kws = corp_ling_dict[i][f'{t}_kw']\n",
    "        kw_templates = []\n",
    "        \n",
    "        for kw in kws:\n",
    "            kw_ = kw.split()\n",
    "            if len(kw_) == 2:\n",
    "                kw1_pos = m.parse(kw_[0])[0].tag.POS\n",
    "                kw2_pos = m.parse(kw_[1])[0].tag.POS\n",
    "\n",
    "                # ADJ + NOUN\n",
    "                if (kw1_pos == 'ADJF') and (kw2_pos == 'NOUN'):\n",
    "                    kw_templates.append(kw)\n",
    "\n",
    "                # NOUN + NOUN (тип генетив)\n",
    "                elif (kw1_pos == 'NOUN') and (kw2_pos == 'NOUN'):\n",
    "                    kw_templates.append(kw)\n",
    "        \n",
    "        print(kw_templates)\n",
    "        corp_ling_dict[i][f'{t}_kw_templates'] = set(kw_templates)\n",
    "# ну такое..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa07487f",
   "metadata": {},
   "source": [
    "## 5. Точность, полнота, F-мера\n",
    "\n",
    "Я не нашла в питоне готовых метрик в данном значении (только в контексте бинарной классификации), поэтому, руководствуясь [соответствующим разделом Википедии](https://en.wikipedia.org/wiki/Precision_and_recall#Definition_(information_retrieval_context)), ниже задала функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "66cfc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(set_new, set_gold):\n",
    "    try:\n",
    "        pr = len(set_new & set_gold) / len(set_new)\n",
    "    except ZeroDivisionError:\n",
    "        pr = 0\n",
    "    return pr\n",
    "\n",
    "def recall(set_new, set_gold):\n",
    "    try: \n",
    "        rec = len(set_new & set_gold) / len(set_gold)\n",
    "    except ZeroDivisionError:\n",
    "        rec = 0\n",
    "    return rec\n",
    "    \n",
    "def f1_score(set_new, set_gold):\n",
    "    try:\n",
    "        pr = precision(set_new, set_gold)\n",
    "        rec = recall(set_new, set_gold)\n",
    "        f1 = 2 * pr * rec / (pr + rec)\n",
    "    except ZeroDivisionError:\n",
    "        f1 = 0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "bfcaf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "3a43fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# для более честного сравнения слова из эталона тоже надо леммантизировать\n",
    "for i in corp_ling_dict.keys():\n",
    "    kw_norm = []\n",
    "    for kw in corp_ling_dict[i]['keywords']:\n",
    "        kw_norm.append(normalize_text(kw))\n",
    "    corp_ling_dict[i]['keywords_norm'] = set(kw_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "18a5ab8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "dda81ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text #1\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.2      |                 0 |   0.2      |                    0 |\n",
      "| recall    |         0 |                   0 | 0.166667 |                 0 |   0.166667 |                    0 |\n",
      "| F1-score  |         0 |                   0 | 0.181818 |                 0 |   0.181818 |                    0 |\n",
      "\n",
      "\n",
      "\n",
      "Text #2\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.2      |                 0 |   0.4      |                    0 |\n",
      "| recall    |         0 |                   0 | 0.111111 |                 0 |   0.222222 |                    0 |\n",
      "| F1-score  |         0 |                   0 | 0.142857 |                 0 |   0.285714 |                    0 |\n",
      "\n",
      "\n",
      "\n",
      "Text #3\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.2      |                 0 |   0.6      |             1        |\n",
      "| recall    |         0 |                   0 | 0.166667 |                 0 |   0.5      |             0.166667 |\n",
      "| F1-score  |         0 |                   0 | 0.181818 |                 0 |   0.545455 |             0.285714 |\n",
      "\n",
      "\n",
      "\n",
      "Text #4\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.2      |                 0 |   0.4      |                    0 |\n",
      "| recall    |         0 |                   0 | 0.166667 |                 0 |   0.333333 |                    0 |\n",
      "| F1-score  |         0 |                   0 | 0.181818 |                 0 |   0.363636 |                    0 |\n",
      "\n",
      "\n",
      "\n",
      "Text #5\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.2      |                 0 |   0.6      |                    0 |\n",
      "| recall    |         0 |                   0 | 0.166667 |                 0 |   0.5      |                    0 |\n",
      "| F1-score  |         0 |                   0 | 0.181818 |                 0 |   0.545455 |                    0 |\n",
      "\n",
      "\n",
      "\n",
      "Text #6\n",
      "| Metric    |   rake_kw |   rake_kw_templates |    tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|---------:|------------------:|-----------:|---------------------:|\n",
      "| precision |         0 |                   0 | 0.4      |                 0 |   0.4      |                    0 |\n",
      "| recall    |         0 |                   0 | 0.222222 |                 0 |   0.222222 |                    0 |\n",
      "| F1-score  |         0 |                   0 | 0.285714 |                 0 |   0.285714 |                    0 |\n",
      "\n",
      "\n",
      "\n",
      "Text #7\n",
      "| Metric    |   rake_kw |   rake_kw_templates |   tr_kw |   tr_kw_templates |   tfidf_kw |   tfidf_kw_templates |\n",
      "|:----------|----------:|--------------------:|--------:|------------------:|-----------:|---------------------:|\n",
      "| precision |  0.4      |            1        |       0 |                 0 |   0.4      |             1        |\n",
      "| recall    |  0.333333 |            0.333333 |       0 |                 0 |   0.333333 |             0.166667 |\n",
      "| F1-score  |  0.363636 |            0.5      |       0 |                 0 |   0.363636 |             0.285714 |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in corp_ling_dict.keys():\n",
    "    print(f'Text #{i}')\n",
    "    df_results = pd.DataFrame({'Metric': ['precision', 'recall', 'F1-score']})\n",
    "    df_results = df_results.set_index('Metric')\n",
    "    \n",
    "    for t1 in ['rake', 'tr', 'tfidf']:\n",
    "        for t2 in ['', '_templates']:\n",
    "            #print(corp_ling_dict[i][f'{t1}_kw{t2}'], corp_ling_dict[i]['keywords_norm'])\n",
    "            pr = precision(corp_ling_dict[i][f'{t1}_kw{t2}'], corp_ling_dict[i]['keywords_norm'])\n",
    "            rec = recall(corp_ling_dict[i][f'{t1}_kw{t2}'], corp_ling_dict[i]['keywords_norm'])\n",
    "            f1 = f1_score(corp_ling_dict[i][f'{t1}_kw{t2}'], corp_ling_dict[i]['keywords_norm'])\n",
    "            df_results[f'{t1}_kw{t2}'] = [pr, rec, f1]\n",
    "    print(df_results.to_markdown())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f21173",
   "metadata": {},
   "source": [
    "**Комментарии к результатам:**\n",
    "* Лучше всего с задачей справляется TF-IDF без шаблонов: в трех случаях дает такие же результаты как TextRank/RAKE, а в четырех показывает более высокие метрики\n",
    "* RAKE почти везде ничего нужного не выделил, только в одном из семи текстов (любопытно, что это также единственный текст, на котором TextRank не заработал, но прокомментировать эту дополнительную дистрибуцию пока не могу)\n",
    "* добавление морфологических шаблонов в целом только ухудшает ситуацию (не остается кандидатов на keywords), при этом в тех случаях, где шаблоны что-то оставили, поднимается precision, но подают recall и F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f8d81e",
   "metadata": {},
   "source": [
    "## 6. Обсуждение ошибок\n",
    "\n",
    "Рассмотрим ошибки на примере текстов 1, 5, 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f26fd166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталон: {'нкря', 'корпус', 'репрезентативность', 'объем корпуса', 'сбалансированность', 'состав текстов'}\n",
      "\n",
      "Эталон (нормализованный): {'корпус', 'репрезентативность', 'объесть корпус', 'нкрить', 'сбалансированность', 'состав текст'}\n",
      "\n",
      "rake (): {'половина xix', 'время'}\n",
      "\n",
      "rake (_templates): set()\n",
      "\n",
      "tr (): {'который', 'репрезентативность', 'период', 'национальный корпус русский язык', 'текст'}\n",
      "\n",
      "tr (_templates): set()\n",
      "\n",
      "tfidf (): {'корпус', 'текст', 'словоупотребление', 'миллион', 'объём'}\n",
      "\n",
      "tfidf (_templates): set()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Эталон:', corp_ling_dict['1']['keywords'], end='\\n\\n')\n",
    "print('Эталон (нормализованный):', corp_ling_dict['1']['keywords_norm'], end='\\n\\n')\n",
    "for t1 in ['rake', 'tr', 'tfidf']:\n",
    "    for t2 in ['', '_templates']:\n",
    "        print(f'{t1} ({t2}):', corp_ling_dict['1'][f'{t1}_kw{t2}'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e420c1",
   "metadata": {},
   "source": [
    "**Комментарий (часть 1):**\n",
    "* проблемы с аббревиатурами и их полным написанием (глагол *нкрить*, до слез)\n",
    "* проблемы со стоп-словами (попали, например, союзы)\n",
    "* проблемы с частыми словами для корпуса тестов (хотя я скорее ожидала, что наоборот, такие слова уйдут из-за особенностей коллекции, но, как мы видим,метрики всё равно выдвигают слова *корпус* и *текст*)\n",
    "* везде сравнивалась с лемматизированным эталоном, но, конечно, пользователю такое выдавать нельзя -- надо обратно изменять слова, согласовывать между собой, а это отдельная непростая задача"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bc59cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталон: {'поверхностный синтаксический анализ', 'синтаксический анализ', 'метод', 'автоматическое извлечение конструкций', 'конструкции', 'русский язык'}\n",
      "\n",
      "Эталон (нормализованный): {'поверхностный синтаксический анализ', 'конструкция', 'русский язык', 'автоматический извлечение конструкция', 'синтаксический анализ', 'метод'}\n",
      "\n",
      "rake (): {'синтаксический связь'}\n",
      "\n",
      "rake (_templates): {'синтаксический связь'}\n",
      "\n",
      "tr (): {'проведение синтаксический анализ текст являться', 'метод весь', 'конструкция', 'работа', 'поиск синтаксически'}\n",
      "\n",
      "tr (_templates): set()\n",
      "\n",
      "tfidf (): {'конструкция', 'синтаксический анализ', 'синтаксический', 'метод', 'точность'}\n",
      "\n",
      "tfidf (_templates): {'синтаксический анализ'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Эталон:', corp_ling_dict['3']['keywords'], end='\\n\\n')\n",
    "print('Эталон (нормализованный):', corp_ling_dict['3']['keywords_norm'], end='\\n\\n')\n",
    "for t1 in ['rake', 'tr', 'tfidf']:\n",
    "    for t2 in ['', '_templates']:\n",
    "        print(f'{t1} ({t2}):', corp_ling_dict['3'][f'{t1}_kw{t2}'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c094fc",
   "metadata": {},
   "source": [
    "**Комментарий (часть 2):**\n",
    "+ проблема с трехсловными ключевыми словами, их не достает никтоб в отличие от двухсловных (ср. *поверхностный синтаксический анализ* и *синтаксический анализ*)\n",
    "* лёгкие глаголы (*являться*), кажется, тоже можно занести в стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e6c63837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эталон: {'метафора', 'китайский язык', 'политический дискурс', 'русский язык', 'антропоморфные метафоры', 'корпусный анализ'}\n",
      "\n",
      "Эталон (нормализованный): {'метафора', 'китайский язык', 'политический дискурс', 'русский язык', 'корпусный анализ', 'антропоморфный метафора'}\n",
      "\n",
      "rake (): {'тема', 'политический дискурс', 'путь', 'русский язык', 'пояс'}\n",
      "\n",
      "rake (_templates): {'политический дискурс', 'русский язык'}\n",
      "\n",
      "tr (): {'анализ', 'политический', 'китайский', 'антропоморфный', 'проект'}\n",
      "\n",
      "tr (_templates): set()\n",
      "\n",
      "tfidf (): {'метафора', 'политический дискурс', 'дискурс', 'политический', 'антропоморфный'}\n",
      "\n",
      "tfidf (_templates): {'политический дискурс'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Эталон:', corp_ling_dict['7']['keywords'], end='\\n\\n')\n",
    "print('Эталон (нормализованный):', corp_ling_dict['7']['keywords_norm'], end='\\n\\n')\n",
    "for t1 in ['rake', 'tr', 'tfidf']:\n",
    "    for t2 in ['', '_templates']:\n",
    "        print(f'{t1} ({t2}):', corp_ling_dict['7'][f'{t1}_kw{t2}'], end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb0cae1",
   "metadata": {},
   "source": [
    "**Комментарий (часть 3):**\n",
    "* иногда находится подчасть ключевого слова (ср. *антропоморфная метафора* и *антропоморфный*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52aedc0",
   "metadata": {},
   "source": [
    "**Предложения по улучшению:**\n",
    "* тщательнее составлять список стоп-слов (добавлять туда союзы, легкие глаголы)\n",
    "* ограничивать длину ключевого слова двумя токенами\n",
    "* мб зашитывать за \"полбалла\", если найдена подстрока ключевого слова\n",
    "* предварительный этап NER и установления синонимии для уменьшения размера словаря и повышения частотностей ключевых слов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
